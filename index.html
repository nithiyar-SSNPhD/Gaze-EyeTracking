<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width,initial-scale=1" />
<title>Study — WebGazer + OpenCV Hybrid Pupil (B3)</title>

<!-- IMPORTANT: ensure opencv.js & opencv_js.wasm are in the same folder -->
<!-- Tell OpenCV where to find the wasm (same folder) -->
<script>
  // locateFile will be used by opencv.js to find the wasm file.
  var Module = {
    locateFile: function(path) {
      // expects opencv_js.wasm (or opencv_js.wasm.gz) to be in same folder
      return path;
    }
  };
</script>

<!-- Load OpenCV.js locally (must exist) -->
<script src="opencv.js"></script>

<!-- Load WebGazer -->
<script src="webgazer.js"></script>

<style>
:root{--primary:#1976d2;--good:#4caf50;--warn:#ffb300;--bad:#e53935}
body,html{margin:0;height:100%;font-family:Arial,Helvetica,sans-serif;background:#fff}
.container{padding:14px;max-width:1200px;margin:0 auto}
.header{display:flex;justify-content:space-between;align-items:center;gap:10px;margin-bottom:12px}
h1{font-size:18px;margin:0}
.controls{display:flex;gap:10px}
button{padding:8px 12px;border:none;border-radius:6px;background:var(--primary);color:#fff;cursor:pointer}
button.secondary{background:#6c757d}
#status{font-size:13px;color:#444;margin-left:8px}
#videoPreview{position:fixed;right:12px;top:12px;width:220px;height:140px;background:#000;border:2px solid #ccc;z-index:999;display:flex;align-items:center;justify-content:center}
#videoPreview video{width:100%;height:100%;object-fit:cover}
#overlayBoxes{position:fixed;right:12px;top:12px;width:220px;height:140px;pointer-events:none}
#pupilReadouts{position:fixed;left:12px;top:12px;background:rgba(255,255,255,0.95);padding:8px;border-radius:8px;border:1px solid #ddd;z-index:999}
#calibrationLayer{position:fixed; inset:0; display:none; z-index:50 }
.cal-dot{position:absolute;width:40px;height:40px;border-radius:50%;background:var(--primary);color:#fff;display:flex;align-items:center;justify-content:center;transform:translate(-50%,-50%)}
#imageContainer{width:100%;height:600px;background:#000;display:flex;align-items:center;justify-content:center}
#stimulus{max-width:100%;max-height:100%;object-fit:contain}
#progressBar{position:fixed;bottom:46px;left:50%;transform:translateX(-50%);width:70%;height:12px;background:#eee;border-radius:8px;overflow:hidden;z-index:50}
#progressFill{height:100%;width:0;background:var(--primary)}
#completionMessage{display:none;position:fixed;top:50%;left:50%;transform:translate(-50%,-50%);background:#fff;padding:18px;border:2px solid #000;border-radius:8px;z-index:60}
pre{white-space:pre-wrap;max-height:220px;overflow:auto}
.small{font-size:13px;color:#333}
</style>
</head>
<body>
<div class="container">
  <div class="header">
    <h1>Study — WebGazer + OpenCV Hybrid Pupil Detection (B3)</h1>
    <div class="controls">
      <button id="startCalibrationBtn">Start Calibration</button>
      <button id="recalibrateBtn" class="secondary" style="display:none">Recalibrate</button>
      <button id="downloadBtn" class="secondary">Download JSON</button>
    </div>
  </div>

  <div id="pupilReadouts" aria-hidden="true">
    <div class="small"><strong>Pupil (px)</strong></div>
    <div>Left: <span id="pLeft">-</span></div>
    <div>Right: <span id="pRight">-</span></div>
    <div>Avg(mm est): <span id="pMM">-</span></div>
  </div>

  <div id="videoPreview" title="Webcam preview (from webgazer)">
    <!-- webgazer will insert <video> element here; we also overlay boxes -->
    <div id="overlayBoxes"></div>
  </div>

  <div id="imageContainer">
    <img id="stimulus" src="assets/3.png" alt="Stimulus">
  </div>

  <div id="progressBar"><div id="progressFill"></div></div>

  <div style="margin-top:12px;">
    <button id="pauseBtn">Pause</button>
    <button id="skipBtn" class="secondary">Skip</button>
    <button id="endBtn" class="secondary">End</button>
    <span id="status" class="small">OpenCV: <span id="cvStatus">loading...</span> ・ WebGazer: <span id="wgStatus">loading...</span></span>
  </div>

  <div style="margin-top:12px;" class="card">
    <div><strong>JSON preview (last 5 samples)</strong></div>
    <pre id="jsonPreview">no data yet</pre>
  </div>

  <div id="completionMessage">
    <h3>Study Complete</h3>
    <p>Download saved as <b>gaze_data_with_pupil.json</b></p>
    <button id="downloadAgain">Download</button>
  </div>
</div>

<!-- Calibration layer -->
<div id="calibrationLayer"></div>

<script>
/* ============================
  Hybrid pupil detection study page
  - Requires: opencv.js (local) and webgazer.js
  - Must be served via http(s) (localhost ok)
  - Pupil outputs appended to gazeData JSON
  - Hybrid algorithm: fast threshold contour, fallback to robust ellipse-fit
  ============================ */

const calibrationTargets = [[10,10],[50,10],[90,10],[10,50],[50,50],[90,50],[10,90],[50,90],[90,90]];
const images = [
  {src:'assets/3.png', duration:8000},
  {src:'assets/4.webp', duration:8000},
  {src:'assets/5.webp', duration:8000}
];

let gazeData = [];
let isCalibrating = false;
let calIndex = 0;
let calSamples = [];
let calResults = [];
let calTargetPx = [];
let holdStart = null;
const calThreshold = 80;
const holdMs = 900;

let webgazerReady = false;
let cvReady = false;
let subjectName = prompt("Enter subject name:") || "Subject";
let isPaused = false;
let curImg = 0;

/* UI elements */
const startCalibrationBtn = document.getElementById('startCalibrationBtn');
const recalibrateBtn = document.getElementById('recalibrateBtn');
const downloadBtn = document.getElementById('downloadBtn');
const pauseBtn = document.getElementById('pauseBtn');
const skipBtn = document.getElementById('skipBtn');
const endBtn = document.getElementById('endBtn');
const pLeftEl = document.getElementById('pLeft');
const pRightEl = document.getElementById('pRight');
const pMMEl = document.getElementById('pMM');
const jsonPreview = document.getElementById('jsonPreview');
const cvStatusEl = document.getElementById('cvStatus');
const wgStatusEl = document.getElementById('wgStatus');
const overlayBoxes = document.getElementById('overlayBoxes');
const calibrationLayer = document.getElementById('calibrationLayer');
const progressFill = document.getElementById('progressFill');
const completion = document.getElementById('completionMessage');
const downloadAgain = document.getElementById('downloadAgain');

/* Simple config for pupil processing frequency */
const PROCESS_EVERY_MS = 66; // ~15 fps

/* WebGazer + OpenCV initialization */
async function initWebGazer(){
  if(typeof webgazer === 'undefined') {
    alert('webgazer.js not found. Place webgazer.js in the same folder.');
    throw new Error('webgazer missing');
  }
  webgazer.params.showVideoPreview = true;
  webgazer.params.showFaceOverlay = false;
  webgazer.params.applyKalmanFilter = true;
  await webgazer.begin();
  // move the webgazer video into our preview container (video element created by webgazer)
  const video = webgazer.getVideoElement();
  if(video){
    video.style.width = '100%'; video.style.height = '100%';
    // append to preview container
    const preview = document.getElementById('videoPreview');
    // remove existing siblings if any
    while(preview.firstChild) preview.removeChild(preview.firstChild);
    preview.appendChild(video);
  }
  wgStatusEl.textContent = 'ready';
  webgazerReady = true;
}

/* Wait for OpenCV runtime to be ready */
function waitForCvReady(){
  return new Promise((resolve,reject)=>{
    if(typeof cv !== 'undefined' && cv && cv.Mat) {
      cvReady = true;
      cvStatusEl.textContent = 'ready';
      resolve();
    } else {
      cv['onRuntimeInitialized'] = () => {
        cvReady = true;
        cvStatusEl.textContent = 'ready';
        resolve();
      };
      // fallback timeout
      setTimeout(()=>{ if(!cvReady){ cvStatusEl.textContent='failed'; reject(new Error('OpenCV load timeout')); } }, 8000);
    }
  });
}

/* Utility: compute mean */
function mean(arr){ if(!arr || arr.length===0) return 0; return arr.reduce((a,b)=>a+b,0)/arr.length; }

/* Eye box heuristics (video natural size) */
function eyeBoxesFromVideo(videoEl){
  const vw = videoEl.videoWidth, vh = videoEl.videoHeight;
  if(!vw || !vh) return null;
  const boxW = Math.round(vw * 0.18);
  const boxH = Math.round(vh * 0.12);
  const leftCx = Math.round(vw * 0.35), rightCx = Math.round(vw * 0.65);
  const cy = Math.round(vh * 0.33);
  const leftBox = { x: Math.max(0,leftCx - Math.round(boxW/2)), y: Math.max(0,cy - Math.round(boxH/2)), width: boxW, height: boxH };
  const rightBox = { x: Math.max(0,rightCx - Math.round(boxW/2)), y: Math.max(0,cy - Math.round(boxH/2)), width: boxW, height: boxH };
  return { leftBox, rightBox };
}

/* Crop ImageData from video natural pixels */
function cropImageData(videoEl, box){
  if(!box || box.width<=0 || box.height<=0) return null;
  // create temporary canvas
  const c = document.createElement('canvas');
  c.width = box.width; c.height = box.height;
  const ctx = c.getContext('2d');
  try{
    ctx.drawImage(videoEl, box.x, box.y, box.width, box.height, 0, 0, box.width, box.height);
    const id = ctx.getImageData(0,0,box.width,box.height);
    return id;
  } catch(e){
    return null;
  }
}

/* Convert ImageData -> cv.Mat (RGBA -> Gray) */
function matFromImageData(imgData){
  const mat = cv.matFromImageData(imgData);
  let gray = new cv.Mat();
  cv.cvtColor(mat, gray, cv.COLOR_RGBA2GRAY);
  mat.delete();
  return gray;
}

/* FAST pupil detection (threshold + contours) */
function fastPupilDetect(grayMat){
  // grayMat is cv.Mat single channel
  let g = grayMat.clone();
  // blur
  cv.GaussianBlur(g, g, new cv.Size(5,5), 0);
  // adaptive threshold or simple threshold using mean - k*std
  const meanStd = cv.meanStdDev(g);
  const meanVal = meanStd[0][0];
  const stdVal = meanStd[1][0];
  let thresh = Math.max(8, meanVal - 0.6*stdVal);
  let bin = new cv.Mat();
  cv.threshold(g, bin, thresh, 255, cv.THRESH_BINARY_INV);
  // morphological open to remove eyelashes
  const M = cv.Mat.ones(3,3,cv.CV_8U);
  cv.morphologyEx(bin, bin, cv.MORPH_OPEN, M);
  // find contours
  let contours = new cv.MatVector();
  let hierarchy = new cv.Mat();
  cv.findContours(bin, contours, hierarchy, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE);
  let best = null, bestArea = 0;
  for(let i=0;i<contours.size();i++){
    const cnt = contours.get(i);
    const area = cv.contourArea(cnt);
    if(area > bestArea){
      bestArea = area;
      best = cnt;
    }
  }
  let result = null;
  if(best && bestArea > 30){ // minimal area threshold
    try{
      if(best.rows >= 5){
        const ellipse = cv.fitEllipse(best);
        result = {center:{x:ellipse.center.x, y:ellipse.center.y}, axes:{major:ellipse.size.height/2, minor:ellipse.size.width/2}, area:bestArea};
      } else {
        // fallback bounding rect
        const rect = cv.boundingRect(best);
        result = {center:{x:rect.x + rect.width/2, y:rect.y + rect.height/2}, axes:{major:rect.height/2, minor:rect.width/2}, area:bestArea};
      }
    } catch(ex){
      // ignore fit problems
      result = null;
    }
  }
  // cleanup
  g.delete(); bin.delete(); contours.delete(); hierarchy.delete(); M.delete();
  return result;
}

/* ROBUST pupil detection (Canny + contours + ellipse) */
function robustPupilDetect(grayMat){
  let g = grayMat.clone();
  cv.medianBlur(g, g, 5);
  let edges = new cv.Mat();
  cv.Canny(g, edges, 40, 80);
  // close gaps
  const K = cv.Mat.ones(3,3,cv.CV_8U);
  cv.morphologyEx(edges, edges, cv.MORPH_CLOSE, K);
  // find contours
  let cnts = new cv.MatVector(), hier = new cv.Mat();
  cv.findContours(edges, cnts, hier, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE);
  let best = null, bestArea = 0;
  for(let i=0;i<cnts.size();i++){
    const c = cnts.get(i);
    const area = cv.contourArea(c);
    if(area > bestArea){
      bestArea = area; best = c;
    }
  }
  let res = null;
  if(best && bestArea > 30){
    try{
      if(best.rows >= 5){
        const ellipse = cv.fitEllipse(best);
        res = {center:{x:ellipse.center.x, y:ellipse.center.y}, axes:{major:ellipse.size.height/2, minor:ellipse.size.width/2}, area:bestArea};
      } else {
        const r = cv.boundingRect(best);
        res = {center:{x:r.x + r.width/2, y:r.y + r.height/2}, axes:{major:r.height/2, minor:r.width/2}, area:bestArea};
      }
    } catch(e){}
  }
  // cleanup
  g.delete(); edges.delete(); K.delete(); cnts.delete(); hier.delete();
  return res;
}

/* Hybrid detection wrapper */
function detectPupilHybrid(imageData){
  if(!cvReady) return null;
  const gray = matFromImageData(imageData);
  let out = fastPupilDetect(gray);
  if(!out){
    out = robustPupilDetect(gray);
  }
  gray.delete();
  return out;
}

/* Drawing overlay boxes for left/right eye on preview (helps tuning) */
function drawEyeOverlay(boxes){
  overlayBoxes.innerHTML = '';
  ['leftBox','rightBox'].forEach(key=>{
    const b = boxes[key];
    if(!b) return;
    const el = document.createElement('div');
    el.style.position='absolute';
    // map video natural pixels to preview size (preview is 220x140)
    const preview = document.getElementById('videoPreview');
    const vid = preview.querySelector('video');
    if(!vid) return;
    const pvRect = vid.getBoundingClientRect();
    const scaleX = pvRect.width / vid.videoWidth;
    const scaleY = pvRect.height / vid.videoHeight;
    el.style.left = (b.x * scaleX) + 'px';
    el.style.top = (b.y * scaleY) + 'px';
    el.style.width = (b.width * scaleX) + 'px';
    el.style.height = (b.height * scaleY) + 'px';
    el.style.border = '2px dashed rgba(255,165,0,0.9)';
    el.style.boxSizing = 'border-box';
    overlayBoxes.appendChild(el);
  });
}

/* Processing pipeline: called from webgazer listener at limited rate */
let lastProcess = 0;
async function processFrameAndRecord(data, t){
  const now = Date.now();
  if(now - lastProcess < PROCESS_EVERY_MS) return; // throttle
  lastProcess = now;

  const videoEl = webgazer.getVideoElement ? webgazer.getVideoElement() : document.querySelector('video');
  if(!videoEl || !videoEl.videoWidth) return;

  const boxes = eyeBoxesFromVideo(videoEl);
  drawEyeOverlay(boxes);

  // left eye
  let leftMetrics = null, rightMetrics = null;
  try {
    const leftImg = cropImageData(videoEl, boxes.leftBox);
    const rightImg = cropImageData(videoEl, boxes.rightBox);
    if(leftImg) leftMetrics = detectPupilHybrid(leftImg);
    if(rightImg) rightMetrics = detectPupilHybrid(rightImg);
  } catch(e){
    console.warn('pupil detect error', e);
  }

  // compute diameters and estimated mm if user provides screen distance & PPD; for now produce px values and optional mm as null
  function toPupilRecord(metrics, box){
    if(!metrics) return null;
    // diameter approximation: average of major/minor * 2 (axes are radii)
    const diameterPx = (metrics.axes.major + metrics.axes.minor);
    return {
      diameter_px: Number(diameterPx.toFixed(2)),
      axes_px: { major: Number(metrics.axes.major.toFixed(2)), minor: Number(metrics.axes.minor.toFixed(2)) },
      center_px: { x: Number(metrics.center.x.toFixed(1)), y: Number(metrics.center.y.toFixed(1)) },
      area_px: Number(metrics.area.toFixed(1)),
      timestamp: Date.now()
    };
  }

  const leftRec = toPupilRecord(leftMetrics, boxes.leftBox);
  const rightRec = toPupilRecord(rightMetrics, boxes.rightBox);
  const avgDiam = (leftRec && rightRec) ? Number(((leftRec.diameter_px + rightRec.diameter_px)/2).toFixed(2)) : (leftRec ? leftRec.diameter_px : (rightRec ? rightRec.diameter_px : null));

  // Map gaze relative coordinates for current image if available
  const imgEl = document.getElementById('stimulus');
  let rel = {x:null,y:null};
  if(imgEl && imgEl.getBoundingClientRect){
    const r = imgEl.getBoundingClientRect();
    let rx = (data.x - r.left) / r.width;
    let ry = (data.y - r.top) / r.height;
    rx = Math.max(0, Math.min(1, rx)); ry = Math.max(0, Math.min(1, ry));
    rel = {x:rx, y:ry};
  }

  // Append to gazeData with rich metrics (compatible with result viewer)
  const sample = {
    imagePath: images[curImg]?.src || null,
    timestamp: t || Date.now(),
    gazePoint: {
      absolute: { x: data.x, y: data.y },
      relative: rel,
      pupil: {
        left: leftRec ? leftRec.diameter_px : null,
        right: rightRec ? rightRec.diameter_px : null
      }
    },
    pupilDetailed: { left: leftRec, right: rightRec, avgDiameter_px: avgDiam },
    subjectName
  };

  gazeData.push(sample);

  // update UI readouts
  pLeftEl.textContent = leftRec ? leftRec.diameter_px : '-';
  pRightEl.textContent = rightRec ? rightRec.diameter_px : '-';
  pMMEl.textContent = '-'; // mm conversion not performed here (needs calibration)

  // update preview of last samples
  const last = gazeData.slice(-5).map(s=>({
    t: s.timestamp,
    img: s.imagePath,
    pupilAvg: s.pupilDetailed.avgDiameter_px,
    left: s.pupilDetailed.left ? s.pupilDetailed.left.diameter_px : null,
    right: s.pupilDetailed.right ? s.pupilDetailed.right.diameter_px : null
  }));
  jsonPreview.textContent = JSON.stringify(last, null, 2);
}

/* WebGazer gaze listener */
function attachWebGazerListener(){
  webgazer.setGazeListener((data, t) => {
    if(!data) return;
    if(isCalibrating){
      // calibration capture - similar to earlier logic
      const target = calTargetPx[calIndex];
      if(!target) return;
      const d = Math.hypot(data.x - target.x, data.y - target.y);
      if(!calSamples[calIndex]) calSamples[calIndex] = [];
      if(d < 200) calSamples[calIndex].push({x:data.x,y:data.y,t});
      if(d < calThreshold){
        if(!holdStart) holdStart = t;
        if(t - holdStart >= holdMs) finalizeCalPoint(calIndex);
      } else holdStart = null;
      return;
    }
    if(!isPaused){
      // smoothing handled by webgazer's Kalman filter if enabled
      processFrameAndRecord(data, t).catch(e=>console.warn(e));
    }
  });
}

/* Calibration UI */
function showCalDot(i){
  calibrationLayer.innerHTML = '';
  const [vw,vh] = calibrationTargets[i];
  const dot = document.createElement('div'); dot.className = 'cal-dot'; dot.textContent = i+1;
  dot.style.left = vw + 'vw'; dot.style.top = vh + 'vh';
  calibrationLayer.appendChild(dot);
  requestAnimationFrame(()=>{
    const r = dot.getBoundingClientRect();
    calTargetPx[i] = { x: r.left + r.width/2, y: r.top + r.height/2 };
    holdStart = null;
  });
}

function startCalibration(){
  isCalibrating = true; calIndex = 0; calSamples = []; calResults = []; calTargetPx = [];
  calibrationLayer.style.display = 'block';
  startCalibrationBtn.style.display = 'none';
  recalibrateBtn.style.display = 'inline-block';
  if(!webgazerReady){
    initWebGazer().then(()=>{ attachWebGazerListener(); showCalDot(0); wgStatusEl.textContent='ready'; }).catch(err=>console.error(err));
  } else {
    showCalDot(0);
  }
}

function finalizeCalPoint(i){
  const s = calSamples[i] || [];
  const m = s.length ? [ mean(s.map(p=>p.x)), mean(s.map(p=>p.y)) ] : [0,0];
  const t = calTargetPx[i];
  const e = Math.hypot(m[0]-t.x, m[1]-t.y);
  calResults[i] = { targetPx: [t.x,t.y], meanPx: m, errorPx: e };
  calIndex++;
  if(calIndex < calibrationTargets.length) showCalDot(calIndex);
  else finishCalibration();
}

function finishCalibration(){
  isCalibrating = false;
  calibrationLayer.style.display = 'none';
  // show summary minimal - for debug use console
  console.log('Calibration finished:', calResults);
}

/* Study flow */
function showImage(i){
  if(i >= images.length){ finishStudy(); return; }
  const img = document.getElementById('stimulus');
  img.src = images[i].src;
  progressFill.style.width = '0%';
  let elapsed = 0; const dur = images[i].duration;
  const step = 100;
  const iv = setInterval(()=>{
    if(!isPaused) {
      elapsed += step;
      const pct = Math.min(100,(elapsed/dur)*100);
      progressFill.style.width = pct + '%';
      if(pct >= 100) { clearInterval(iv); curImg++; showImage(curImg); }
    }
  }, step);
}

function startStudy(){
  curImg = 0;
  showImage(curImg);
}

function finishStudy(){
  completion.style.display = 'block';
  downloadJSON();
}

/* Download JSON */
function downloadJSON(){
  const json = {
    metadata: { timestamp: (new Date()).toISOString(), subjectName, viewport:{ width: innerWidth, height: innerHeight }, images: images },
    gazeData
  };
  const blob = new Blob([JSON.stringify(json,null,2)], {type:'application/json'});
  const a = document.createElement('a');
  a.href = URL.createObjectURL(blob);
  a.download = 'gaze_data_with_pupil.json';
  a.click();
}

/* Controls */
startCalibrationBtn.onclick = ()=> { startCalibration(); waitForCvReady().catch(e=>console.warn(e)); };
recalibrateBtn.onclick = ()=> { calibrationLayer.style.display='none'; startCalibration(); };
downloadBtn.onclick = ()=> { downloadJSON(); };
pauseBtn.onclick = ()=> { isPaused = !isPaused; pauseBtn.textContent = isPaused ? 'Resume' : 'Pause'; };
skipBtn.onclick = ()=> { curImg++; showImage(curImg); };
endBtn.onclick = ()=> { finishStudy(); };
downloadAgain.onclick = ()=> { downloadJSON(); };

/* Initialize: wait for cv and webgazer */
(async function init(){
  try {
    await waitForCvReady();
    // initialize webgazer but do NOT begin until calibration click to avoid camera prompt early
    // we still show webgazer status as loaded once begin() is called
    wgStatusEl.textContent = 'click Start Calibration (camera prompt)';
  } catch(e){
    console.error('OpenCV load error', e);
    alert('OpenCV failed to load. Check opencv.js and opencv_js.wasm are present and that you run via http(s).');
  }
})();

</script>
</body>
</html>


